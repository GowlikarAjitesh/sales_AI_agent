# Sales Insight AI Agent

This project provides a natural-language sales analytics assistant using:
- Sales API  
- LLM (Google Gemini 2.5 Flash)  + LLM Math modules
- CLI interface  

## Setup

```bash
python -m venv venv
source venv/Scripts/activate    # Windows Git Bash
pip install -r requirements.txt
```

## Environment Variable

Generate a Google Gemini API key and add it to your `.env` file:

```
GOOGLE_API_KEY=your_api_key_here
```

## Run the Project

Your project is ready.  
Give your prompts and the AI Sales Agent will reply with insights.

```
python run.py
```
## Example Queries

 #### - What were total sales in Q3 2025?
 #### - Please show me the top 5 products by revenue last month.
 #### - Compare sales growth between the North and South regions this year.
 #### - Which salesperson has the highest conversion rate?
 #### - Forecast next month's revenue based on current trends.
 #### - List underperforming products with less than 10 units sold in the last 30 days.

## Design Decisions

#### - LLM + Math Chain: Used Gemini 2.5 Flash for natural language understanding and LLMMathChain (LangChain) to safely execute computed expressions from LLM output.
#### - Mock Sales API: Implemented a lightweight in-memory database (sales_data.py) simulating real API latency and structure for rapid prototyping.
#### - CLI-First Interface: Prioritized terminal interaction for quick iteration and debugging; GUI/web layer can be added later.
#### - Structured Prompt Templates: Used few-shot prompting with role ("You are a senior sales analyst") to improve response consistency.
#### - Error Handling & Fallbacks: If math parsing fails, agent asks clarifying questions instead of crashing.


## Brief Reflection

#### - This project successfully transforms raw sales data into actionable insights using conversational AI, making analytics accessible to non-technical users.
#### - The combination of Gemini’s reasoning and LangChain’s math tools enabled accurate numerical answers without hardcoding logic.
#### - While the CLI works well for demos, real-world adoption would benefit from a dashboard or Slack integration.


## Most Challenging Aspect?

#### - Safely evaluating dynamic math expressions generated by the LLM.
#### - The model sometimes outputs malformed or ambiguous formulas (e.g., revenue * 1.15 without context), so implementing robust parsing, validation, and sandboxed execution via LLMMathChain was critical to avoid errors or security risks.


## What Would You Improve?

#### - Add a web dashboard (Streamlit/FastAPI) for visual charts and historical trends.
#### - Integrate a real database (PostgreSQL) and caching (Redis) for production scale.
#### - Support multi-turn conversations with memory to track context like "Compare to last quarter" after a prior query.
#### - Add authentication & role-based access for enterprise use.
#### - Allow export results to CSV/PDF directly from CLI.


## Interesting Decisions

#### - Using Gemini 2.5 Flash over Pro: Chose Flash for cost-efficiency and low latency in CLI — critical for snappy UX.
#### - Zero external dependencies beyond LangChain & Google GenAI: Kept bundle lightweight (~15 MB venv).
#### - Simulated API delays (time.sleep(0.3)) to mimic real network behavior during development.
#### - Color-coded CLI output using rich for better readability of tables and highlights.
